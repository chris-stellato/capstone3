{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.time_series_functions import *\n",
    "# from pandas.plotting import register_matplotlib_converters\n",
    "# register_matplotlib_converters()\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "# from keras.callbacks import EarlyStopping#, ModelCheckpoint\n",
    "from keras.metrics import MeanAbsolutePercentageError\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 11323 entries, 1990-01-01 to 2020-12-31\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   ds            11323 non-null  datetime64[ns]\n",
      " 1   y             11323 non-null  float64       \n",
      " 2   avg_temp      11323 non-null  float64       \n",
      " 3   precip_accum  11323 non-null  float64       \n",
      " 4   swe           11323 non-null  float64       \n",
      " 5   hist_avg_y    11323 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 619.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "                    ds    y  avg_temp  precip_accum  swe  hist_avg_y\n",
       " ds                                                                 \n",
       " 1990-01-01 1990-01-01  6.5      19.0           5.6  4.8    6.437742\n",
       " 1990-01-02 1990-01-02  6.9      16.0           5.7  4.8    6.502258\n",
       " 1990-01-03 1990-01-03  6.9       2.0           5.7  4.8    6.673226)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in master df\n",
    "base_df = csv_with_datetime('data/master_df.csv', 'ds')\n",
    "df = base_df.copy()\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.info(), df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functionize to take a year and produce graph, rmse, and lift over historical avg model. \n",
    "#function requires a minimum of 6000 samples, set pred_year accordingly\n",
    "#function designed to work with project-specific column names, edits would be required to work with other data\n",
    "\n",
    "def year_eval_lstm(model, pred_year, master_df):\n",
    "    df = master_df.copy()\n",
    "    \n",
    "    #making desired year last year in sample data\n",
    "    samp_df = df[:pred_year]\n",
    "\n",
    "    #trimming sample data to 6000 records total\n",
    "    samp_df = samp_df.iloc[-6000:]\n",
    "\n",
    "    # convert datetime column to continuous integer\n",
    "    samp_df['ds'] = pd.to_datetime(df['ds']).sub(pd.Timestamp(df['ds'].iloc[0])).dt.days\n",
    "    \n",
    "    #don't pass in historical y to model\n",
    "    samp_df.drop('hist_avg_y', axis=1, inplace=True)\n",
    "    \n",
    "    # scale entire dataframe except y column \n",
    "    scale_df = samp_df.copy()\n",
    "    for column in scale_df.columns:\n",
    "      if column != 'y':\n",
    "        scaler = StandardScaler()\n",
    "        # print (scale_df[column].values.shape)\n",
    "        holder = scaler.fit_transform(scale_df[column].values.reshape(-1,1))\n",
    "        scale_df[column] = holder.reshape(len(scale_df),)\n",
    "        \n",
    "    #test size depends if year is leap year or not\n",
    "    test_size = 365\n",
    "    if int(pred_year)%4 == 0:\n",
    "        test_size = 366\n",
    "        \n",
    "    #these variables can't be changed without retraining models used in this project\n",
    "    n_prev = 400 #model was trained on this input shape\n",
    "    predict_steps = 30 #model was trained on this output shape\n",
    "    \n",
    "    #utilizes windowize_data function\n",
    "    X, y = windowize_data(scale_df, n_prev, 'y', predict_steps)\n",
    "    X_test = X[-test_size:]\n",
    "    y_test = y[-test_size:]\n",
    "    \n",
    "    #use model to make predictions and make 0 the lower limit of predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred[y_pred<0] = 0\n",
    "\n",
    "    \n",
    "    #grab predictions at 1-day, 14-days, and 30-days out for each day of the year\n",
    "    day_1_pred = y_pred[:,:1]          \n",
    "    day_14_pred = y_pred[:,13:14]\n",
    "    day_30_pred = y_pred[:,-1:]\n",
    "    \n",
    "    #collect and print rmse for 1-day, 14-days, and 30-days prediction sets\n",
    "    day_1_rmse  = sqrt(mean_squared_error(y_test[:,:1], day_1_pred))\n",
    "    day_14_rmse = sqrt(mean_squared_error(y_test[:,13:14], day_14_pred))\n",
    "    day_30_rmse = sqrt(mean_squared_error(y_test[:,-1:], day_30_pred))\n",
    "    print(f'For prediction year {pred_year}:')\n",
    "    print(f'1-Day RMSE = {day_1_rmse}')\n",
    "    print(f'14-Day RMSE = {day_14_rmse}')\n",
    "    print(f'30-Day RMSE = {day_30_rmse}')\n",
    "    \n",
    "    #collect historical average set, calculate rmse over actuals, and compare lift over historical average\n",
    "    hist_avg_set = df[pred_year]['hist_avg_y']\n",
    "    hist_avg_rmse = sqrt(mean_squared_error(y_test[:,:1], hist_avg_set))\n",
    "    \n",
    "    day_1_lift = 1-(day_1_rmse/hist_avg_rmse)\n",
    "    day_14_lift = 1-(day_14_rmse/hist_avg_rmse)\n",
    "    day_30_lift = 1-(day_30_rmse/hist_avg_rmse)\n",
    "    \n",
    "    #print lifts over historical average\n",
    "    print(f'Historical average vs. actuals RMSE: {hist_avg_rmse}')\n",
    "    print('\\n')\n",
    "    print('Model lift over historical average method')\n",
    "    print(f'1-Day: {day_1_lift*100}%')\n",
    "    print(f'14-Day: {day_14_lift*100}%')\n",
    "    print(f'30-Day: {day_30_lift*100}%')\n",
    "    \n",
    "    return day_1_rmse, day_14_rmse, day_30_rmse, hist_avg_rmse, day_1_lift, day_14_lift, day_30_lift\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v12 = keras.models.load_model('models/LSTM_v12.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For prediction year 2016:\n",
      "1-Day RMSE = 13.749036666436169\n",
      "14-Day RMSE = 17.941302037724856\n",
      "30-Day RMSE = 18.755011760686155\n",
      "Historical average vs. actuals RMSE: 40.42520060663747\n",
      "\n",
      "\n",
      "Model lift over historical average method\n",
      "1-Day: 65.98894635001838%\n",
      "14-Day: 55.618520703694294%\n",
      "30-Day: 53.605643313476236%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13.749036666436169,\n",
       " 17.941302037724856,\n",
       " 18.755011760686155,\n",
       " 40.42520060663747,\n",
       " 0.6598894635001837,\n",
       " 0.556185207036943,\n",
       " 0.5360564331347624)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_eval_lstm(lstm_v12, '2016', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
